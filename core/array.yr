import std.traits;

extern (C) GC_malloc (ulong) : ptr!(void);

struct Array (T) {
    length : ulong,
    raw : ptr!(int)
}

def opIndex (T, I) (a : Array!(T), id : I) : ref T {
    return (a.raw + (cast:ulong (id) * T.sizeof)).T;
}

def opIndex (T, U) (a : ptr!(T), b : range!(U)) : Array!T {
    return Array!(T) (cast:ulong (b.scd - b.fst), a);
}


def cstArray (len : ulong, size : ubyte) : ptr!(void) {
    let array = GC_malloc (len * size);
    return (len, array).ptr;
}

def opIndex if (isDecimal!(I)) (T of [U], U, I) (a : T, rng : range!(I)) {    
    if (rng.fst < rng.scd) {
        let len = rng.scd - rng.fst;
        let aux = a.tupleof;
        let ret = (cast:ulong (len),
                   cast:ptr!(ubyte) (aux.1)
                       + (cast:ulong (rng.fst) * U.sizeof));
        
        return cast:[U] (ret);
    } else if (rng.fst == rng.scd) {
        return [U ; 0UL];
    } else 
        return null;
}

def opBinary('+', T of [U], U) (a : T, b : T) : T {
    let c = [U ; a.length + b.length];    
    for it in 0U .. a.length
        c [it] = a [it];

    for it in 0U .. b.length
        c [it + a.length] = b [it];

    return c;        
}

def opAssign ("+=", T of [U], U) (ref a : T, b : T) : ref T {
    a = a + b;
    return a;
}
